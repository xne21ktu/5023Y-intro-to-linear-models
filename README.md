# 5023Y-intro-to-linear-models

Lesson 1: Intro to stats:

In today's lesson we learned how to calculate mean and SD between two groups (crossed and self plant groups from a datat set of Darwin). Using this we then learnt how to estimate standard error and confidence intervals in order to describe how much confidence we have that our experiments would capture the true population mean.

Lesson 2: Intro linear models:

In today's lesson I learned how to use the lm function to compare means, calculate SED and CI, as well as checking assumptions of a linear model. We determined the answer to darwin's question and that the null can be rejected

Lesson 3: Testing:

In today's lesson, we learnt to calculate P-values and test statistical significance for our experiments using linear models. We also compared the linear model structures for producing a paired vs. unpaired t-test. We learnt about type 1 and 2 errors and how confidence intervals and effect sizes can be used to assess these, with a requirement of repeating experiments. We learnt that reliance on reporting P-values is uninformative and can be misleading. Instead reporting estimates and confidence intervals allows us to report our levels of uncertainty, and provides results which are more informative for comparitive studies.

Lesson 4: Regression:

In today's lesson, we learnt about how Linear models can not only test differences of means in categorical groupings, but also test relationships between continuous variables (regression). We explored the relationship between the explanatory variable (x axis - density) and response variable (y axis - wood hardness), using the straight line equation. 
In linear regressions, the intercept is the value of y when x = 0, and through the use of centering,  we learnt how to make the intercept more useful. We continued to learn that the same assumptions apply, including that the residuals (unexplained variance around the regression line) is normal distributed and of equal variance. When these assumptions have been checked, we are then able to make predictions of wood hardness (y values) from density (x values), using confidence intervals to measure any uncertainty.

Lesson 5: ANOVA:

In today's lesson, we learnt how to use ANOVA tables for our linear model. The tables partition the variance into signal(s) and noise, which can be compared using an F-test. This creates a 'signal-to-noise' ratio, or the variability explained by the slope of the linear model, vs unexplained variance. ANOVA can be used to for complex analyses where many comparisons can be made. An initial F-test can provide evidence for whether there are any differences at all, reducing the risk of overtesting and the false positives (Type 1 errors) that can be generated.
